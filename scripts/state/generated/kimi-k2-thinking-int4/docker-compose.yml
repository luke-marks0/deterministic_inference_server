services:
  vllm:
    image: "vllm/vllm-openai:v0.11.1rc6"
    container_name: "vllm_kimi_k2_thinking"
    gpus: "all"
    ipc: "host"
    restart: "unless-stopped"
    ulimits:
      memlock: -1
      stack: 67108864
    ports:
      - "8001:8000"
    volumes:
      - "/home/ubuntu/deterministic_inference_server/scripts/state/hf:/data/hf"
      - "/home/ubuntu/deterministic_inference_server/scripts/artifacts:/artifacts"
    environment:
      CUBLAS_WORKSPACE_CONFIG: ":4096:8"
      CUDA_DEVICE_MAX_CONNECTIONS: "1"
      HF_HOME: "/data/hf"
    command:
      - "--model"
      - "moonshotai/Kimi-K2-Thinking"
      - "--revision"
      - "5b64d2a87e32f24d6231ef01ee676f65e54496a7"
      - "--served-model-name"
      - "kimi-k2-thinking"
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "8000"
      - "--dtype=auto"
      - "--tensor-parallel-size=8"
      - "--pipeline-parallel-size=1"
      - "--max-model-len=262144"
      - "--seed=424242"
      - "--max-num-seqs=1"
      - "--max-num-batched-tokens=32768"
      - "--enforce-eager"
      - "--trust-remote-code"
      - "--enable-auto-tool-choice"
      - "--tool-call-parser=kimi_k2"
      - "--reasoning-parser=kimi_k2"
      - "--disable-log-requests"
