{
  "base_config": "standard-base.json",
  "integrity": {
    "expected_snapshot_manifest": "manifests/kimi-k2-thinking/{revision}.sha256"
  },
  "model": {
    "id": "moonshotai/Kimi-K2-Thinking",
    "locked_at_utc": "2026-02-17T00:00:00Z",
    "revision": "5b64d2a87e32f24d6231ef01ee676f65e54496a7",
    "served_name": "kimi-k2-thinking"
  },
  "profile": {
    "description": "Reference profile for Kimi-K2-Thinking with deterministic-oriented vLLM flags.",
    "id": "kimi-k2-thinking-int4"
  },
  "runtime": {
    "compose_project_name": "vllm_kimi_k2_thinking",
    "container_name": "vllm_kimi_k2_thinking",
    "host_port": 8001,
    "image": "docker.io/vllm/vllm-openai@sha256:d8d39b59e909d2378ac4feeb191f7e7b6f1342477dc66b7c47cec89e9985ad8a",
    "environment": {
      "PYTORCH_CUDA_ALLOC_CONF": "expandable_segments:True"
    }
  },
  "vllm": {
    "flags": [
      "--dtype=float16",
      "--tensor-parallel-size=8",
      "--pipeline-parallel-size=1",
      "--max-model-len=768",
      "--max-num-batched-tokens=256",
      "--gpu-memory-utilization=0.95",
      "--trust-remote-code",
      "--enable-auto-tool-choice",
      "--tool-call-parser=kimi_k2",
      "--reasoning-parser=qwen3"
    ]
  }
}
