{
  "schema_version": 1,
  "kind": "vllm.deterministic_run_bundle",
  "created_at": "2026-02-21T15:37:51Z",
  "run_id": "2d8f97811601e07e15972d6e4042f9bb136df4fcc347c33c639b2ad05319dd25",
  "manifest_id": "8d8a917f51ae1f7a68504dff56ac2ca9fc4a9078eedb543e6723c98549e303aa",
  "lock_id": "9d73fe5f41a7b815218a8accc43b1e741e0349835489ab09c79a2e3fbcd257a0",
  "requests_digest": "63e3c472d05f8e6e99f092d656717b26ceb1be36fc2b16470f0d8d8ad419b70a",
  "hardware_fingerprint": {
    "captured_at": "2026-02-21T15:37:50Z",
    "platform": {
      "system": "Linux",
      "release": "6.8.0-1040-nvidia",
      "machine": "x86_64",
      "python_version": "3.10.12"
    },
    "accelerator_vendor": "nvidia",
    "gpu_models": [
      "NVIDIA B200",
      "NVIDIA B200"
    ],
    "gpu_compute_capabilities": [
      "10.0",
      "10.0"
    ],
    "driver_versions": [
      "570.195.03",
      "570.195.03"
    ],
    "env": {
      "CUBLAS_WORKSPACE_CONFIG": ":4096:8",
      "CUDA_VISIBLE_DEVICES": "0",
      "LANG": "C.UTF-8",
      "MKL_NUM_THREADS": "1",
      "OMP_NUM_THREADS": "1",
      "PYTHONHASHSEED": "0",
      "TZ": "UTC"
    }
  },
  "hardware_conformant": true,
  "hardware_non_conformance_reasons": [],
  "runtime_closure_digest": "d6a31f9f110fb26fef255c14283f6847549b90ee9e0ab2d8f280a352ef1ea4b6",
  "runtime_closure_matches_lock": true,
  "determinism_grade": "conformant",
  "runtime_environment": {
    "PYTHONHASHSEED": "0",
    "OMP_NUM_THREADS": "1",
    "MKL_NUM_THREADS": "1",
    "CUBLAS_WORKSPACE_CONFIG": ":4096:8",
    "CUDA_DEVICE_ORDER": "PCI_BUS_ID",
    "CUDA_VISIBLE_DEVICES": "0",
    "VLLM_BATCH_INVARIANT": "1",
    "VLLM_ENABLE_V1_MULTIPROCESSING": "0",
    "LANG": "C.UTF-8",
    "LC_ALL": "C.UTF-8",
    "TZ": "UTC"
  },
  "determinism_controls": {
    "seed": 424242,
    "deterministic_failure_policy": "warn_only",
    "python_random_seeded": true,
    "numpy": {
      "available": true,
      "seeded": true,
      "version": "2.2.6"
    },
    "torch": {
      "available": false,
      "seeded": false,
      "error": "No module named 'torch'"
    },
    "warnings": [
      "Torch controls unavailable: No module named 'torch'"
    ]
  },
  "software_metadata": {
    "python": {
      "version": "3.10.12",
      "executable": "/home/ubuntu/deterministic_inference_server/.venv/bin/python"
    },
    "vllm": {
      "available": false,
      "error": "No module named 'vllm'"
    },
    "torch": {
      "available": false,
      "error": "No module named 'torch'"
    }
  },
  "artifact_integrity": {
    "enabled": true,
    "checked_count": 0,
    "skipped_count": 14,
    "failure_count": 0,
    "checked": [],
    "skipped": [
      {
        "index": 0,
        "name": "model.weight",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 1,
        "name": "model.tokenizer",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 2,
        "name": "model.tokenizer",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 3,
        "name": "model.tokenizer",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 4,
        "name": "model.config",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 5,
        "name": "model.config",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 6,
        "name": "model.chat_template",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 7,
        "name": "python.package.vllm",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 8,
        "name": "python.package.torch",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 9,
        "name": "python.package.triton",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 10,
        "name": "cuda.userspace.cuda_toolkit",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 11,
        "name": "cuda.userspace.cublas",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 12,
        "name": "cuda.userspace.cudnn",
        "reason": "no_explicit_local_path"
      },
      {
        "index": 13,
        "name": "cuda.userspace.nccl",
        "reason": "no_explicit_local_path"
      }
    ]
  },
  "batch_trace": {
    "policy": "fixed",
    "schedule": "batch_invariant",
    "max_num_seqs": 1,
    "max_num_batched_tokens": 4096,
    "steps": [
      {
        "step_index": 0,
        "batch_size": 1,
        "request_ids": [
          "req-0001"
        ],
        "prompt_token_counts": [
          59
        ],
        "max_tokens_per_request": [
          32
        ],
        "batch_token_budget": 91,
        "replay_arrival_ms": []
      }
    ]
  },
  "capture": {
    "tokens": {
      "enabled": true,
      "status": "captured"
    },
    "logits": {
      "enabled": false,
      "status": "disabled",
      "note": "TODO: logits capture intentionally not implemented yet."
    },
    "activations": {
      "enabled": false,
      "status": "disabled",
      "note": "TODO: activation capture intentionally not implemented yet."
    },
    "engine_trace": {
      "enabled": false,
      "status": "disabled",
      "note": "TODO: vLLM engine trace capture intentionally not implemented yet."
    }
  },
  "paths": {
    "manifest": "manifest.used.json",
    "lock": "lock.used.json",
    "tokens": "tokens.json",
    "run_log": "run_log.json"
  },
  "notes": {
    "logits": "configured via capture.logits but intentionally no-op",
    "activations": "configured via capture.activations but intentionally no-op",
    "engine_trace": "configured via capture.engine_trace but intentionally no-op"
  }
}
