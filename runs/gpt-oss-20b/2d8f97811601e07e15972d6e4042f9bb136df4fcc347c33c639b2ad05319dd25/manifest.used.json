{
  "schema_version": 1,
  "kind": "vllm.deterministic_inference_manifest",
  "metadata": {
    "name": "gpt-oss-20b",
    "description": "Spec-aligned deterministic manifest for gpt-oss-20b.",
    "created_at": "2026-02-18T00:00:00Z",
    "owners": [
      "ml-platform@example.com"
    ]
  },
  "determinism": {
    "strict_hardware": false,
    "compare": {
      "tokens": {
        "rule": "exact"
      },
      "logits": {
        "rule": "exact"
      },
      "activations": {
        "rule": "absrel",
        "atol": 0.0,
        "rtol": 0.0
      },
      "engine_trace": {
        "rule": "exact"
      }
    }
  },
  "hardware": {
    "constraints": {
      "accelerator_vendor": "nvidia",
      "gpu_arch_min_cc": "8.0",
      "allowed_gpu_models": []
    },
    "record": {
      "capture_collect_env": true,
      "capture_nvidia_smi": true,
      "capture_driver_versions": true,
      "capture_pcie_topology": false
    }
  },
  "artifacts": {
    "store": {
      "type": "cas",
      "path": "state/store"
    },
    "lockfile": "manifests/gpt-oss-20b/manifest.lock.json"
  },
  "software_stack": {
    "python": {
      "version": "3.11.8",
      "packages": [
        {
          "name": "vllm",
          "source": {
            "type": "wheel",
            "digest": "97ff5ba0c359962f3d12625d286990614fb33e122568012992d2e623165a5f8b"
          }
        },
        {
          "name": "torch",
          "source": {
            "type": "wheel",
            "digest": "11ffd779e02064e548a470e03c44ea1abf964dbea1e52f79241617c25faf3937"
          }
        },
        {
          "name": "triton",
          "source": {
            "type": "wheel",
            "digest": "f57d52ad61f69302c692c028da244ef32828fdf14dc711b657ce8a4db7495cc3"
          }
        }
      ]
    },
    "compiled_extensions": []
  },
  "cuda_stack": {
    "userspace": {
      "cuda_toolkit": {
        "version": "12.x",
        "digest": "621e155eb77a75e6f2c4d4cf65177ffd2aa9a2625712443bc35657dc48bc141e"
      },
      "cublas": {
        "version": "12.x",
        "digest": "7b42da2c381b1945ab964ab47d5e3eb55c68e5bfe9713adc2a34ff8ad58f3827"
      },
      "cudnn": {
        "version": "9.x",
        "digest": "1218bedb143a5ce463ea551e7530e9c3dd803364b130439b4c182e1aaa5dfa4d"
      },
      "nccl": {
        "version": "2.x",
        "digest": "c12e64d2c825bbe6b87b17a77c8ecd78e9bdc7126a38867a878e690478ca56e0"
      }
    },
    "env": {
      "CUBLAS_WORKSPACE_CONFIG": ":4096:8",
      "CUDA_DEVICE_ORDER": "PCI_BUS_ID",
      "CUDA_VISIBLE_DEVICES": "0"
    },
    "driver_policy": "pinned_or_recorded"
  },
  "runtime": {
    "env": {
      "PYTHONHASHSEED": "0",
      "OMP_NUM_THREADS": "1",
      "MKL_NUM_THREADS": "1"
    },
    "locale": {
      "lang": "C.UTF-8",
      "tz": "UTC"
    },
    "threads": {
      "omp_num_threads": 1,
      "mkl_num_threads": 1
    },
    "network_policy": "online_allowed",
    "execution": {
      "backend": "openai_compatible",
      "base_url": "http://127.0.0.1:8002",
      "timeout_seconds": 600,
      "deterministic_failure_policy": "warn_only",
      "vllm_image": "docker.io/vllm/vllm-openai@sha256:8c9aaddfa6011b9651d06834d2fb90bdb9ab6ced4b420ec76925024eb12b22d0"
    }
  },
  "vllm": {
    "mode": "server",
    "reproducibility": {
      "enable_batch_invariance": true,
      "enable_v1_multiprocessing": false
    },
    "env": {
      "VLLM_BATCH_INVARIANT": "1",
      "VLLM_ENABLE_V1_MULTIPROCESSING": "0"
    },
    "engine_args": {
      "model": "openai/gpt-oss-20b",
      "trust_remote_code": false,
      "dtype": "bfloat16",
      "tensor_parallel_size": 1,
      "pipeline_parallel_size": 1,
      "max_model_len": 32768
    }
  },
  "model": {
    "weights": {
      "source": {
        "type": "huggingface",
        "repo": "openai/gpt-oss-20b",
        "revision": "6cee5e81ee83917806bbde320786a8fb61efebee"
      },
      "files": [
        {
          "path": "model.safetensors",
          "digest": "3dafb871d4b7ff010adf0e0ac7c126cb4ebbc5e59afcb3e92ff577f8deec2088"
        }
      ]
    },
    "tokenizer": {
      "files": [
        {
          "path": "tokenizer.json",
          "digest": "7370efe91361693d223a3a2b9a3509854b604cd62296a54cf96d5c819e94f30f"
        },
        {
          "path": "tokenizer_config.json",
          "digest": "bc1c6e874c815f7a485be8077edadf65713af631e1df68774a55a78c6d48be5c"
        },
        {
          "path": "special_tokens_map.json",
          "digest": "aa293059725e2700ec0f07527913dcb6c8374f188f4e5373a16dd6254902fdb5"
        }
      ]
    },
    "config": {
      "files": [
        {
          "path": "config.json",
          "digest": "50baf1b656f540e3bf5cb315e98162b15d35389fbff6f01ffd65705a44f0889a"
        },
        {
          "path": "generation_config.json",
          "digest": "02ee46cd77c089cd0c62e54b2634ec5e714c6a9f6e325180ba6bee357268b0c1"
        }
      ]
    },
    "chat_template": {
      "file": {
        "path": "chat_template.jinja",
        "digest": "38d78b456b6053f1b4eaf0c151c0cc9ec7426c2c7a29bc0f6bb032f91936726b"
      }
    }
  },
  "inference": {
    "requests": [
      {
        "id": "req-0001",
        "kind": "completion",
        "prompt": "Write exactly one sentence that says the server is healthy.",
        "sampling": {
          "temperature": 0.0,
          "top_p": 0.95,
          "top_k": 50,
          "max_tokens": 32,
          "seed": 424242
        },
        "stop": {
          "sequences": [],
          "token_ids": []
        }
      }
    ],
    "batching": {
      "policy": "fixed",
      "schedule": "batch_invariant",
      "max_num_seqs": 1,
      "max_num_batched_tokens": 4096,
      "fixed_request_order": true,
      "concurrency": 1
    }
  },
  "capture": {
    "tokens": true,
    "logits": {
      "enabled": false,
      "scope": "chosen_only",
      "dtype": "float16",
      "capture_prefill": false,
      "capture_decode": false
    },
    "activations": {
      "enabled": false,
      "hooks": []
    },
    "engine_trace": {
      "enabled": false,
      "events": []
    }
  },
  "outputs": {
    "directory": "runs/gpt-oss-20b/${run_id}",
    "golden": {
      "enabled": false
    },
    "bundle_policy": {
      "include": [
        "manifest",
        "lock",
        "tokens",
        "run_log"
      ],
      "retention_days": 30
    }
  }
}
