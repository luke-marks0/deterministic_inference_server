{
  "model": "openai/gpt-oss-20b",
  "provider": "gpt-oss-20b",
  "parameters": {
    "n_prompts": 1,
    "max_tokens": 32,
    "seed": 424242,
    "temperature": 0.0,
    "top_k": 50,
    "top_p": 0.95,
    "prompt_token_ids_sha256": "b2b85f4da48e481a69f54311899b1a61bdae2a88720bafc5502fbf2df2040b20"
  },
  "tokenizer": {
    "digest": "2036b4b352b724d9513ab9402fb362d59acc31bec3bd136e43283dc5cb9b1b3a",
    "revision": "6cee5e81ee83917806bbde320786a8fb61efebee",
    "files": [
      {
        "path": "tokenizer.json",
        "digest": "7370efe91361693d223a3a2b9a3509854b604cd62296a54cf96d5c819e94f30f"
      },
      {
        "path": "tokenizer_config.json",
        "digest": "bc1c6e874c815f7a485be8077edadf65713af631e1df68774a55a78c6d48be5c"
      },
      {
        "path": "special_tokens_map.json",
        "digest": "aa293059725e2700ec0f07527913dcb6c8374f188f4e5373a16dd6254902fdb5"
      }
    ]
  },
  "conversations": [
    [
      {
        "role": "user",
        "content": "Write exactly one sentence that says the server is healthy."
      }
    ]
  ],
  "sequences": [
    {
      "prompt_token_ids": [
        87,
        114,
        105,
        116,
        101,
        32,
        101,
        120,
        97,
        99,
        116,
        108,
        121,
        32,
        111,
        110,
        101,
        32,
        115,
        101,
        110,
        116,
        101,
        110,
        99,
        101,
        32,
        116,
        104,
        97,
        116,
        32,
        115,
        97,
        121,
        115,
        32,
        116,
        104,
        101,
        32,
        115,
        101,
        114,
        118,
        101,
        114,
        32,
        105,
        115,
        32,
        104,
        101,
        97,
        108,
        116,
        104,
        121,
        46
      ],
      "output_token_ids": [
        198,
        26178,
        38193,
        2500,
        382,
        261,
        1621,
        328,
        9862,
        13,
        1416,
        1309,
        316,
        18135,
        480,
        472,
        261,
        3176,
        13,
        623,
        26628,
        25,
        392,
        976,
        6052,
        382,
        261,
        2195,
        484,
        382,
        220,
        19
      ]
    }
  ],
  "decoded_output_text": [
    "token_id:198 token_id:26178 token_id:38193 token_id:2500 token_id:382 token_id:261 token_id:1621 token_id:328 token_id:9862 token_id:13 token_id:1416 token_id:1309 token_id:316 token_id:18135 token_id:480 token_id:472 token_id:261 token_id:3176 token_id:13 token_id:623 token_id:26628 token_id:25 token_id:392 token_id:976 token_id:6052 token_id:382 token_id:261 token_id:2195 token_id:484 token_id:382 token_id:220 token_id:19"
  ]
}
